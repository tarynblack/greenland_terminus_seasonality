{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# -- import local custom modules\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import GlacierClass as gc\n",
    "import plotutils as gpu\n",
    "\n",
    "# -- import other modules\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "from astropy.timeseries import LombScargle\n",
    "import copy\n",
    "import matplotlib.colors as colors\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import nisardev as nisar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative path for file geodatabase containing glacier information\n",
    "fgdb = '../Greenland_Glaciers.gdb' # if file is shp rather than gdb, will need to update file read lines in the next cell\n",
    "# -- File geodatabase layer names\n",
    "termini_layer = 'glacier_termini'\n",
    "points_layer = 'glacier_points'\n",
    "boxes_layer = 'glacier_boxes'\n",
    "\n",
    "# Other data files (for plotting and velocity analysis)\n",
    "oceanmask_file = '../miscdata/GimpOceanMask_90m/GimpOceanMask_90m.shp' # Howat/MEaSUREs ocean mask, https://nsidc.org/data/nsidc-0714/versions/1 \n",
    "basins_file = '../miscdata/GRE_Basins_IMBIE2_v1.3/GRE_Basins_IMBIE2_v1.3.shp' # Rignot Greenland drainage basins, http://imbie.org/imbie-3/drainage-basins/\n",
    "velocity_file = '../miscdata/GL_vel_mosaic_Annual_01Dec19_30Nov20/GL_vel_mosaic_Annual_01Dec19_30Nov20_*_v03.0' # Joughin/MEaSUREs annual velocity for 2019-2020, https://nsidc.org/data/nsidc-0725/versions/4\n",
    "\n",
    "# Relative path to save analysis output\n",
    "outpath = '../analysis/'\n",
    "\n",
    "# set figure style to The Cryosphere style parameters\n",
    "gpu.globalDesignProperties('pub-cryo')\n",
    "fw = gpu.figureWidth('pub-cryo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND CLEAN GLACIER DATA FILES\n",
    "\n",
    "# -- Load glacier terminus data\n",
    "termini = gpd.read_file(fgdb, layer=termini_layer, driver='FileGDB')\n",
    "termini['Source_Date'] = pd.to_datetime(termini.Source_Date, errors='coerce')\n",
    "termini['Glacier_ID'] = termini.Glacier_ID.astype('int')\n",
    "termini['Quality_Flag'] = termini.Quality_Flag.astype('int')\n",
    "# -- Reduce to Sentinel-1 termini only (will be 2015 onwards)\n",
    "termini = termini[termini.Sensor == 'SEN1']\n",
    "# -- Drop potential date duplicates\n",
    "termini.drop_duplicates(subset=['Glacier_ID', 'Source_Date'], keep='first', inplace=True)\n",
    "\n",
    "# -- Load glacier point locations\n",
    "points = gpd.read_file(fgdb, layer=points_layer, driver='FileGDB')\n",
    "points.sort_values(by='Glacier_ID', inplace=True)\n",
    "points.set_index('Glacier_ID', drop=True, inplace=True)\n",
    "\n",
    "# -- Load glacier reference boxes\n",
    "refboxes = gpd.read_file(fgdb, layer=boxes_layer, driver='FileGDB')\n",
    "refboxes.sort_values(by='Glacier_ID', inplace=True)\n",
    "refboxes.set_index('Glacier_ID', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET SCOPE OF GLACIERS AND TIME\n",
    "\n",
    "# -- all glacier IDs in database\n",
    "GIDS = termini.Glacier_ID.unique()\n",
    "# -- exclude glaciers that were added for polar bear project\n",
    "GIDS = GIDS[GIDS < 800] \n",
    "# -- remove glaciers with only a single entry (not valuable for seasonal analysis)\n",
    "single_termini = []\n",
    "for g in GIDS:\n",
    "    i = len(termini[termini.Glacier_ID == g])\n",
    "    if i == 1:\n",
    "        single_termini.append(g)\n",
    "single_termini\n",
    "GIDS = list(set(GIDS) - set(single_termini))\n",
    "# -- get list of glaciers digitized at six-day frequency\n",
    "GIDS6 = [3, 7, 9, 13, 17, 19, 20, 21, 22, 23, 24, 32, 34, 35, 42, 46, 51, 65, 71, 81]\n",
    "GIDS6_seasonal = [3, 7, 9, 13, 17, 19, 20, 21, 22, 23, 24, 32, 34, 35, 42, 46, 51, 71, 81]\n",
    "# -- get list of glaciers digitized at monthly frequency\n",
    "GIDSm = list(set(GIDS) - set(GIDS6))\n",
    "\n",
    "# -- Get range of dates and years\n",
    "DATE_START = termini.Source_Date.min()\n",
    "DATE_END = termini.Source_Date.max()\n",
    "YEAR_START = DATE_START.year\n",
    "YEAR_END = DATE_END.year\n",
    "YEARS = range(YEAR_START, YEAR_END+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRUCT AN OBSERVATION TIME SERIES FOR EACH GLACIER\n",
    "\n",
    "# -- Initialize dictionary of Glacier objects to store glacier information\n",
    "all_glaciers = {id: gc.Glacier(id) for id in GIDS}\n",
    "for id in all_glaciers:\n",
    "    all_glaciers[id].refbox = refboxes.loc[id].geometry\n",
    "    all_glaciers[id].officialname = points.loc[id].Official_Name\n",
    "    all_glaciers[id].greenlandicname = points.loc[id].Greenlandic_Name\n",
    "    all_glaciers[id].alternativename = points.loc[id].Alternative_Name\n",
    "\n",
    "# -- Loop through glaciers to construct time series\n",
    "for id in GIDS:\n",
    "\n",
    "    # get reference line and all observations for GID\n",
    "    glacier = termini.query('Glacier_ID == @id')\n",
    "    \n",
    "    # loop through all observations and process data\n",
    "    for n in range(len(glacier)):\n",
    "        observation = glacier.iloc[n]\n",
    "\n",
    "        # create a Terminus Observation object for a row in geodataframe\n",
    "        obs = gc.TerminusObservation(gid=int(observation.Glacier_ID),\n",
    "                                     qflag=observation.Quality_Flag,\n",
    "                                     termination='',\n",
    "                                     imageid=observation.Image_ID,\n",
    "                                     sensor=observation.Sensor,\n",
    "                                     date=pd.to_datetime(observation.Source_Date),\n",
    "                                     terminus=observation.geometry,\n",
    "                                     referencebox=all_glaciers[id].refbox)\n",
    "        \n",
    "        # add glacier observation to time series\n",
    "        all_glaciers[id].addObservation(obs)\n",
    "    \n",
    "    # update all attribute series for glacier\n",
    "    all_glaciers[id].updateObservedValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manuscript data and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC DATASET STATS\n",
    "\n",
    "# -- Get number of glaciers in each dataset\n",
    "print(f'There are {len(GIDS)} glaciers in the entire dataset.')\n",
    "print(f'There are {len(GIDSm)} glaciers in the monthly dataset.')\n",
    "print(f'There are {len(GIDS6)} glaciers in the six-day dataset.')\n",
    "\n",
    "# -- Get number of termini in each dataset\n",
    "termini = termini[termini.Glacier_ID.isin(GIDS)]\n",
    "monthly_termini = termini[termini.Glacier_ID.isin(GIDSm)]\n",
    "sixday_termini = termini[termini.Glacier_ID.isin(GIDS6)]\n",
    "\n",
    "print(f'\\nThere are {len(termini)} termini in the entire dataset.')\n",
    "print(f'There are {len(monthly_termini)} termini in the monthly dataset, or an average of {len(monthly_termini)/len(GIDSm):.0f} per glacier.')\n",
    "print(f'There are {len(sixday_termini)} termini in the six-day dataset, or an average of {len(sixday_termini)/len(GIDS6):.0f} per glacier.')\n",
    "\n",
    "# -- Get number of images used for each dataset\n",
    "print(f'\\nWe used {len(termini.Image_ID.unique())} SAR mosaics for the entire dataset. This includes different versions of the same date range.')\n",
    "print(f'Combining versions, we used {len(termini.Image_ID.str[-17:].unique())} mosaic date ranges for the entire dataset.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: Map of study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP OF STUDY AREA\n",
    "\n",
    "# -- Load datasets\n",
    "coastline = gpd.read_file(oceanmask_file)\n",
    "coastline.to_crs(points.crs, inplace=True)\n",
    "basins = gpd.read_file(basins_file)\n",
    "basins.to_crs(points.crs, inplace=True)\n",
    "basins = basins[basins.SUBREGION1 != 'ICE_CAP']\n",
    "\n",
    "# -- Plot Greenland outline, drainage basins (labeled), and glacier locations\n",
    "fig, ax = plt.subplots(figsize=(fw, fw*2), subplot_kw={'projection': ccrs.NorthPolarStereo(central_longitude=-45, true_scale_latitude=70)})\n",
    "coastline.plot(ax=ax, linewidth=0.25, color='dimgray')\n",
    "basins.plot(ax=ax, edgecolor='black', facecolor='none')\n",
    "basins.apply(lambda x: ax.annotate(text=x['SUBREGION1'], xy=x.geometry.centroid.coords[0], ha='center'), axis=1)\n",
    "points[points.index.isin(GIDSm)].plot(ax=ax, markersize=15, color='dodgerblue', edgecolor='black', linewidth=0.75, zorder=2, label='Monthly glaciers')\n",
    "points[points.index.isin(GIDS6)].plot(ax=ax, markersize=15, color='darkorange', edgecolor='black', linewidth=0.75, zorder=2, label='Six-day glaciers')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=2)\n",
    "\n",
    "# -- Narrow plot bounds slightly\n",
    "xmin, ymin, xmax, ymax = coastline.total_bounds\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "# -- Set gridline properties to display as lat/lon and below other features\n",
    "gl = ax.gridlines(\n",
    "    transform=ccrs.Geodetic(), \n",
    "    draw_labels=True,\n",
    "    x_inline=False,\n",
    "    y_inline=False,\n",
    "    color='dimgray',\n",
    "    zorder=0.5)\n",
    "gl.top_labels = True\n",
    "gl.bottom_labels = False\n",
    "gl.left_labels = True\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'rotation': 0}\n",
    "gl.ylabel_style = {'rotation': 0}\n",
    "\n",
    "plt.savefig('../figures/fig1_map.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP GLACIER IDS INTO EACH REGION\n",
    "GIDS_CW = [x for x in (list(range(1,18))) if x in GIDS]\n",
    "GIDS_NW = [x for x in (list(range(18,91))) if x in GIDS]\n",
    "GIDS_NO = [x for x in (list(range(91,106)) + [210]) if x in GIDS]\n",
    "GIDS_NE = [x for x in (list(range(106,125)) + [211, 212, 213, 214, 237, 239]) if x in GIDS]\n",
    "GIDS_SE = [x for x in (list(range(125,203)) + list(range(215, 236)) + [238, 801, 802, 803, 804]) if x in GIDS]\n",
    "GIDS_SW = [x for x in (list(range(203,210)) + [236]) if x in GIDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables S1 and S2: Names and locations of monthly and six-day glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of glacier IDs, names, and terminus centroids for monthly glaciers\n",
    "def get_centroid(gid, epsg):\n",
    "    \"\"\"Find single point (centroid) that represents all termini for a glacier.Returns lat and lon.\"\"\"\n",
    "    all_centroids = gpd.GeoDataFrame(geometry=termini[termini.Glacier_ID == gid].geometry.centroid)\n",
    "    one_centroid = all_centroids.dissolve().centroid.to_crs(f'epsg:{epsg}')\n",
    "    latlon = f'({one_centroid.y[0]:.3f}, {one_centroid.x[0]:.3f})'\n",
    "    return one_centroid.y, one_centroid.x, latlon\n",
    "\n",
    "tableS1 = pd.DataFrame(index=GIDSm, columns=['Name', 'Coordinates'])\n",
    "tableS1['Name'] = [all_glaciers[g].getGlacierName() for g in tableS1.index.values]\n",
    "tableS1['Coordinates'] = [get_centroid(g, epsg=4326)[2] for g in tableS1.index.values]\n",
    "tableS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of glacier IDs, names, and terminus centroids for six-day glaciers\n",
    "tableS2 = pd.DataFrame(index=GIDS6, columns=['Name', 'Coordinates'])\n",
    "tableS2['Name'] = [all_glaciers[g].getGlacierName() for g in tableS2.index.values]\n",
    "tableS2['Coordinates'] = [get_centroid(g, epsg=4326)[2] for g in tableS2.index.values]\n",
    "tableS2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrend(data):\n",
    "    \"\"\"Detrend data based on first and last values (Ben Smith suggestion).\"\"\"\n",
    "    y_0, y_1 = data[0], data[-1]\n",
    "    trend = pd.Series(index=data.index, dtype='float64')\n",
    "    trend.iloc[0] = y_0\n",
    "    trend.iloc[-1] = y_1\n",
    "    trend = trend.interpolate(method='linear')\n",
    "    data_detrended = data - trend\n",
    "    return data_detrended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Monthly glacier lengths for all glaciers (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of monthly relative lengths for each glacier\n",
    "annual_months = pd.date_range(start='2015-01-01', end='2021-12-01', freq='MS').to_period('M')\n",
    "gml_gids = range(1,240)\n",
    "glaciers_monthly_lengths = pd.DataFrame(index=gml_gids, columns=annual_months)\n",
    "\n",
    "# compute length per month for all glaciers (mostly just filtering down the six-day glaciers)\n",
    "for id in GIDS:\n",
    "    glacier = all_glaciers[id]\n",
    "    if not glacier.lengths.empty:\n",
    "        lengths = pd.Series(glacier.lengths.values, index=glacier.dates.dt.to_period('M'))\n",
    "        monthly_lengths = lengths[~lengths.index.duplicated(keep='first')]\n",
    "        rel_monthly_lengths = monthly_lengths - monthly_lengths.mean()\n",
    "        glaciers_monthly_lengths.loc[id] = rel_monthly_lengths\n",
    "\n",
    "# set colormap properties\n",
    "cmap = copy.copy(plt.cm.get_cmap('seismic_r'))\n",
    "cmap.set_bad(color='gray') # plot missing data as gray\n",
    "\n",
    "# plot \"heatmap\" of relative glacier lengths over time for monthly data\n",
    "fig, ax = plt.subplots(figsize=(fw*2, fw*1.5))\n",
    "ax.grid(False)\n",
    "gml = ax.pcolormesh(\n",
    "    glaciers_monthly_lengths.values.astype('float'), \n",
    "    cmap=cmap, \n",
    "    norm=colors.SymLogNorm(linthresh=0.1, vmin=-1, vmax=1))\n",
    "ax.set_xticks(range(0,len(annual_months)+1,12))\n",
    "ax.set_xticklabels(['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022'])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Glacier ID')\n",
    "ax.set_title('Relative glacier length')\n",
    "plt.colorbar(gml, extend='both', label='Relative length (km)')\n",
    "\n",
    "plt.savefig('../figures/fig2_lengths_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary figures 2,3: length plots for individual glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for the 20 six-day glaciers in one plot\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in GIDS6:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "    # qflags = pd.Series(glacier.extract('qflag').values, index=glacier.dates)\n",
    "\n",
    "    n = GIDS6.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    # ax[n].scatter(lengths[qflags==0].index, lengths[qflags==0].values, marker='.', label='Certain position')\n",
    "    # ax[n].scatter(lengths[qflags!=0].index, lengths[qflags!=0].values, marker='.', color='red', zorder=3)\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-1].axis('off')\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/figS2_sixday_lengths.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for select monthly glaciers in one plot\n",
    "# 5 - Eqip Sermia\n",
    "# 18 - Umiammakku Sermiat\n",
    "# 93 - Petermann\n",
    "# 120 - Daugaard-Jensen\n",
    "# 153 - Kangerlussuaq\n",
    "# 175 - Helheim\n",
    "figs2_ids = [5, 18, 93, 120, 153, 175]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, figsize=(fw*2,4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in figs2_ids:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "    # qflags = pd.Series(glacier.extract('qflag').values, index=glacier.dates)\n",
    "\n",
    "    n = figs2_ids.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    # ax[n].scatter(lengths[qflags==0].index, lengths[qflags==0].values, marker='.', label='Certain position')\n",
    "    # ax[n].scatter(lengths[qflags!=0].index, lengths[qflags!=0].values, marker='.', color='red', zorder=3)\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    elif id in [120, 153]:\n",
    "        name_parts = name.split('Gletsjer')\n",
    "        name_2line = name_parts[0] + '\\nGletsjer'\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/figS3_select_monthly_lengths.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for the 12 monthly CW GrIS glaciers in one plot\n",
    "cw_m = [x for x in GIDS_CW if x not in GIDS6]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=3, sharex=True, figsize=(fw*2,6))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in cw_m:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = cw_m.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_CW.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for the 53 monthly NW GrIS glaciers in three plots\n",
    "nw_m = [x for x in GIDS_NW if x not in GIDS6]\n",
    "nw_ma = nw_m[0:21]\n",
    "nw_mb = nw_m[21:42]\n",
    "nw_mc = nw_m[42:]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in nw_ma:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = nw_ma.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_NW-A.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NW monthly glaciers plot B\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in nw_mb:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = nw_mb.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_NW-B.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NW monthly glaciers plot C\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=3, sharex=True, figsize=(fw*2,6))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in nw_mc:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = nw_mc.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "ax[-1].axis('off')\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_NW-C.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for the 13 monthly NO GrIS glaciers\n",
    "no_m = [x for x in GIDS_NO if x not in GIDS6]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=3, sharex=True, figsize=(fw*2,7))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in no_m:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = no_m.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "ax[-1].axis('off')\n",
    "ax[-2].axis('off')\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_NO.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for the 25 monthly NE GrIS glaciers in two plots\n",
    "ne_m = [x for x in GIDS_NE if x not in GIDS6]\n",
    "ne_ma = ne_m[0:15]\n",
    "ne_mb = ne_m[15:]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=3, sharex=True, figsize=(fw*2,7))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in ne_ma:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = ne_ma.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_NE-A.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE glacier lengths - B\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=3, sharex=True, figsize=(fw*2,6))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in ne_mb:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = ne_mb.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "ax[-1].axis('off')\n",
    "ax[-2].axis('off')\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_NE-B.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths for the 88 monthly SE GrIS glaciers in two plots\n",
    "se_m = [x for x in GIDS_SE if x not in GIDS6]\n",
    "se_ma = se_m[0:21]\n",
    "se_mb = se_m[21:42]\n",
    "se_mc = se_m[42:63]\n",
    "se_md = se_m[63:84]\n",
    "se_me = se_m[84:]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in se_ma:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = se_ma.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_SE-A.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE glacier lengths - B\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in se_mb:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = se_mb.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_SE-B.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE glacier lengths - C\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in se_mc:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = se_mc.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_SE-C.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE glacier lengths - D\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, figsize=(fw*2,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in se_md:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = se_md.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_SE-D.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE glacier lengths - E\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, figsize=(fw*2,4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in se_me:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths = lengths - lengths.mean()\n",
    "\n",
    "    n = se_me.index(id)\n",
    "    ax[n].plot(lengths.index, lengths.values, '.-')\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "ax[-1].axis('off')\n",
    "ax[-2].axis('off')\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Length (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/monthly_lengths_SE-E.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: determine seasonal cycle significance for every glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOMB-SCARGLE PERIODOGRAM\n",
    "\n",
    "glaciers_significance = pd.Series(index=GIDS, dtype='bool')\n",
    "glaciers_sig_90 = pd.Series(index=GIDS, dtype='bool')\n",
    "glaciers_sig_99 = pd.Series(index=GIDS, dtype='bool')\n",
    "\n",
    "for id in GIDS:\n",
    "    # get length data for glacier\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates).dropna()\n",
    "    \n",
    "    # detrend data and get time as decimal years\n",
    "    lengths_detrend = detrend(lengths)\n",
    "    dt = (lengths_detrend.index - pd.to_datetime(f'{YEAR_START}-01-01')) / np.timedelta64(1, 'Y')\n",
    "\n",
    "    # compute Lomb-Scargle periodogram\n",
    "    ls = LombScargle(dt, lengths_detrend.values)\n",
    "    frequency, power = ls.autopower(minimum_frequency=2/len(YEARS), maximum_frequency=4)\n",
    "    # -- get power at annual frequency\n",
    "    # TODO: at exactly 1.0 or at the peak that's around 1.0?\n",
    "    annual = ls.power(frequency=1.0)\n",
    "    # -- get p=0.05 (95% confidence) for the peak between 0.8 and 1.2 1/yr\n",
    "    # -- (have to specify min/max frequencies, otherwise it will calculate for whatever is highest peak)\n",
    "    p90, p95, p99 = ls.false_alarm_level([0.1, 0.05, 0.01], minimum_frequency=0.8, maximum_frequency=1.2, method='baluev')\n",
    "\n",
    "    # determine if peak is significant at p=.05 (95%) level\n",
    "    significant = annual > p95\n",
    "    glaciers_significance.loc[id] = significant\n",
    "\n",
    "    # test sensitivity of Lomb-Scargle analysis to other thresholds\n",
    "    sig_90 = annual > p90\n",
    "    glaciers_sig_90.loc[id] = sig_90\n",
    "    sig_99 = annual > p99\n",
    "    glaciers_sig_99.loc[id] = sig_99\n",
    "\n",
    "    # plot\n",
    "    # fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "    # # -- plot data and detrended data\n",
    "    # ax1.plot(lengths - lengths.mean(), color='gray', linewidth=0.5, label='original')\n",
    "    # ax1.plot(lengths_detrend, linewidth=1, label='detrended')\n",
    "    # ax1.set_title(f'{glacier.getGlacierName()} length')\n",
    "    # ax1.set_xlabel('Time')\n",
    "    # ax1.set_ylabel('Length (km)')\n",
    "    # ax1.legend(loc='upper right', bbox_to_anchor=[0.999, 0.999])\n",
    "    # # -- plot periodogram\n",
    "    # ax2.plot(frequency, power, label='Lomb-Scargle')\n",
    "    # ax2.axvline(1.0, color='darkorange', linewidth=0.5, label='annual frequency')\n",
    "    # ax2.axhline(p95, ls='--', color='gray', label='p=0.05')\n",
    "    # ax2.axhline(p90, ls='--', color='black', label='p=0.1')\n",
    "    # ax2.set_title(f'Lomb-Scargle periodogram\\nSignificant annual period = {significant}')\n",
    "    # ax2.set_xlabel('Frequency ($yr^{-1}$)')\n",
    "    # ax2.set_ylabel('Lomb-Scargle power')\n",
    "    # ax2.set_ylim([0, 1])\n",
    "    # ax2.legend()\n",
    "    # plt.savefig(f'../analysis/lomb-scargle_periodogram/{id:03}_periodogram.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLACIERS WITH SIGNIFICANT ANNUAL CYCLE (periodic_glaciers)\n",
    "periodic_glaciers = glaciers_significance[glaciers_significance == True]\n",
    "GIDS_seasonal = periodic_glaciers.index\n",
    "print(f'Between {YEAR_START} and {YEAR_END}, {100*len(periodic_glaciers)/len(glaciers_significance):.1f}% (n={len(periodic_glaciers)}) of Greenland\\'s outlet glaciers had a significant annual cycle in length.')\n",
    "\n",
    "# glaciers with significant annual cycle at other thresholds\n",
    "periodic_90 = glaciers_sig_90[glaciers_sig_90 == True]\n",
    "periodic_99 = glaciers_sig_99[glaciers_sig_99 == True]\n",
    "print(f'At the 90% threshold, {100*len(periodic_90)/len(glaciers_sig_90):.1f}% (n={len(periodic_90)}) of glaciers had significant seasonality.')\n",
    "print(f'At the 99% threshold, {100*len(periodic_99)/len(glaciers_sig_99):.1f}% (n={len(periodic_99)}) of glaciers had significant seasonality.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHICH GLACIERS ARE *NOT* SEASONAL?\n",
    "GIDS_not_seasonal = list(set(GIDS) - set(GIDS_seasonal))\n",
    "GIDS_not_seasonal = sorted(GIDS_not_seasonal)\n",
    "GIDS_not_seasonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1: Regional breakdown of significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGIONAL BREAKDOWN OF GLACIERS WITH SIGNIFICANT ANNUAL CYCLE\n",
    "regional_significance = pd.DataFrame(index=['CW', 'NW', 'NO', 'NE', 'SE', 'SW', 'GrIS'], columns=['significant', 'total'])\n",
    "regional_significance.loc['CW'] = [np.count_nonzero(periodic_glaciers.index.isin(GIDS_CW)), len(GIDS_CW)]\n",
    "regional_significance.loc['NW'] = [np.count_nonzero(periodic_glaciers.index.isin(GIDS_NW)), len(GIDS_NW)]\n",
    "regional_significance.loc['NO'] = [np.count_nonzero(periodic_glaciers.index.isin(GIDS_NO)), len(GIDS_NO)]\n",
    "regional_significance.loc['NE'] = [np.count_nonzero(periodic_glaciers.index.isin(GIDS_NE)), len(GIDS_NE)]\n",
    "regional_significance.loc['SE'] = [np.count_nonzero(periodic_glaciers.index.isin(GIDS_SE)), len(GIDS_SE)]\n",
    "regional_significance.loc['SW'] = [np.count_nonzero(periodic_glaciers.index.isin(GIDS_SW)), len(GIDS_SW)]\n",
    "regional_significance.loc['GrIS'] = [len(periodic_glaciers), len(GIDS)]\n",
    "regional_significance['percent'] = 100 * regional_significance['significant'] / regional_significance['total']\n",
    "regional_significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: compute seasonality for every glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframe to store seasonality stats for all glaciers\n",
    "seasonality = pd.DataFrame(\n",
    "    index=GIDS_seasonal,\n",
    "    columns=['Median Advance DOY', 'Median Advance Day', 'Median Retreat DOY', 'Median Retreat Day', 'Retreat Duration', 'Median Magnitude (km)'])\n",
    "# initialize dataframes to store DOYs of greatest advance and retreat for all glaciers\n",
    "max_advance_doy = pd.DataFrame(columns=YEARS, index=GIDS_seasonal).sort_index()\n",
    "max_retreat_doy = pd.DataFrame(columns=YEARS, index=GIDS_seasonal).sort_index()\n",
    "annual_seasonality = pd.DataFrame(columns=YEARS, index=GIDS_seasonal).sort_index()\n",
    "\n",
    "for id in GIDS_seasonal:\n",
    "    # get length data for glacier id\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates).dropna()\n",
    "\n",
    "    # initialize dataframe to store individual glacier seasonality stats\n",
    "    glacier_seasonality = pd.DataFrame(\n",
    "        index=YEARS, \n",
    "        columns=['MaxLength', 'MaxDate', 'MaxDOY', 'MinLength', 'MinDate', 'MinDOY', 'Duration', 'Magnitude'])\n",
    "    glacier_seasonality = glacier_seasonality.astype({\n",
    "        'MaxLength': 'float', 'MaxDate': 'datetime64[ns]', 'MaxDOY': 'float', \n",
    "        'MinLength': 'float', 'MinDate': 'datetime64[ns]', 'MinDOY': 'float', \n",
    "        'Duration': 'float', 'Magnitude': 'float'})\n",
    "\n",
    "    if not lengths.empty:\n",
    "        # detrend length time series\n",
    "        # find peak dates, then detrend, then find peak values.\n",
    "        lengths_detrend = detrend(lengths)\n",
    "        \n",
    "        # get annual peak values and dates\n",
    "        peaks, _ = signal.find_peaks(lengths, width=2)\n",
    "        peak_lengths = lengths_detrend[peaks]\n",
    "        annual_greatest_advance = pd.DataFrame(\n",
    "            index=peak_lengths.index.year.unique(), \n",
    "            columns=['length', 'date', 'doy'])\n",
    "        annual_greatest_advance = annual_greatest_advance.astype(\n",
    "            {'length': 'float', 'date': 'datetime64[ns]', 'doy': 'float'})\n",
    "        annual_greatest_advance['length'] = peak_lengths.groupby(peak_lengths.index.year).max().values\n",
    "        annual_greatest_advance['date'] = pd.to_datetime(peak_lengths.groupby(peak_lengths.index.year).idxmax())\n",
    "        annual_greatest_advance['doy'] = pd.to_datetime(annual_greatest_advance['date'].values).dayofyear\n",
    "\n",
    "        # get annual trough values and dates\n",
    "        troughs, _ = signal.find_peaks(-1*lengths, width=2)\n",
    "        trough_lengths = lengths_detrend[troughs]\n",
    "        annual_greatest_retreat = pd.DataFrame(\n",
    "            index=trough_lengths.index.year.unique(), \n",
    "            columns=['length', 'date', 'doy'])\n",
    "        annual_greatest_retreat = annual_greatest_retreat.astype(\n",
    "            {'length': 'float', 'date': 'datetime64[ns]', 'doy': 'float'})\n",
    "        annual_greatest_retreat['length'] = trough_lengths.groupby(trough_lengths.index.year).min().values\n",
    "        annual_greatest_retreat['date'] = pd.to_datetime(trough_lengths.groupby(trough_lengths.index.year).idxmin())\n",
    "        annual_greatest_retreat['doy'] = pd.to_datetime(annual_greatest_retreat['date'].values).dayofyear\n",
    "\n",
    "    # add glacier data to summary dataframe\n",
    "    # -- peak lengths, dates, and day-of-years\n",
    "    glacier_seasonality['MaxLength'] = annual_greatest_advance['length']\n",
    "    glacier_seasonality['MaxDate'] = annual_greatest_advance['date']\n",
    "    glacier_seasonality['MaxDOY'] = annual_greatest_advance['doy']\n",
    "    # -- trough lengths, dates, and day-of-years, accounting for when retreat peaks in following year\n",
    "    for y in YEARS:\n",
    "        if y == YEARS[0]: # for the first year in the dataframe\n",
    "            if y in annual_greatest_retreat.index: # if there is a retreat in that year\n",
    "                if y not in annual_greatest_advance.index: # if there is not an advance in that year, set the retreat values as normal\n",
    "                    glacier_seasonality.at[y, 'MinDate'] = annual_greatest_retreat.loc[y]['date']\n",
    "                    glacier_seasonality.at[y, 'MinLength'] = annual_greatest_retreat.loc[y]['length']\n",
    "                    glacier_seasonality.at[y, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy']\n",
    "                elif annual_greatest_retreat.loc[y]['date'] > annual_greatest_advance.loc[y]['date']: # if the retreat comes after the advance, set the retreat values as normal\n",
    "                    glacier_seasonality.at[y, 'MinDate'] = annual_greatest_retreat.loc[y]['date']\n",
    "                    glacier_seasonality.at[y, 'MinLength'] = annual_greatest_retreat.loc[y]['length']\n",
    "                    glacier_seasonality.at[y, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy']\n",
    "        if y > YEARS[0]: # for the other years in the dataframe\n",
    "            if y in annual_greatest_retreat.index: # if there is a retreat in that year\n",
    "                if y not in annual_greatest_advance.index: # if there is not an advance in that year\n",
    "                    if y-1 in annual_greatest_advance.index and annual_greatest_retreat.loc[y]['date'] < annual_greatest_advance.loc[y-1]['date'] + pd.Timedelta(365, 'D'):\n",
    "                        # if there is an advance in the previous year and the retreat this year actually follows from last year, set this year's retreat values in last year's row and add 365 to the DOY\n",
    "                        glacier_seasonality.at[y-1, 'MinDate'] = annual_greatest_retreat.loc[y]['date']\n",
    "                        glacier_seasonality.at[y-1, 'MinLength'] = annual_greatest_retreat.loc[y]['length']\n",
    "                        glacier_seasonality.at[y-1, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy'] + 365\n",
    "                    elif y-1 not in annual_greatest_advance.index and annual_greatest_retreat.loc[y]['date'].month <= 4:\n",
    "                        # if there is not an advance in the previous year and this year's retreat occurs in or before April, set this year's retreat values in last year's row and add 365 to the DOY\n",
    "                        glacier_seasonality.at[y-1, 'MinDate'] = annual_greatest_retreat.loc[y]['date']\n",
    "                        glacier_seasonality.at[y-1, 'MinLength'] = annual_greatest_retreat.loc[y]['length']\n",
    "                        glacier_seasonality.at[y-1, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy'] + 365\n",
    "                    else: # otherwise set this year's retreat values as normal\n",
    "                        glacier_seasonality.at[y, 'MinDate'] = annual_greatest_retreat.loc[y]['date']\n",
    "                        glacier_seasonality.at[y, 'MinLength'] = annual_greatest_retreat.loc[y]['length']\n",
    "                        glacier_seasonality.at[y, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy']\n",
    "                elif annual_greatest_retreat.loc[y]['date'] > annual_greatest_advance.loc[y]['date']:\n",
    "                    # if this year's retreat occurs after this year's advance, set this year's retreat values as normal\n",
    "                    glacier_seasonality.at[y, 'MinDate'] = annual_greatest_retreat.loc[y]['date']\n",
    "                    glacier_seasonality.at[y, 'MinLength'] = annual_greatest_retreat.loc[y]['length']\n",
    "                    glacier_seasonality.at[y, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy']\n",
    "                elif annual_greatest_retreat.loc[y]['date'] < annual_greatest_advance.loc[y]['date']:\n",
    "                    # if this year's retreat occurs before this year's advance, set this year's retreat values in last year's row and add 365 to the DOY\n",
    "                    glacier_seasonality.at[y-1, 'MinDate'] = annual_greatest_retreat.loc[y]['date']      \n",
    "                    glacier_seasonality.at[y-1, 'MinLength'] = annual_greatest_retreat.loc[y]['length']      \n",
    "                    glacier_seasonality.at[y-1, 'MinDOY'] = annual_greatest_retreat.loc[y]['doy'] + 365\n",
    "    # -- compute duration and magnitude of seasonality\n",
    "    glacier_seasonality['Duration'] = [\n",
    "        x.days for x in glacier_seasonality['MinDate'] - glacier_seasonality['MaxDate']]\n",
    "    glacier_seasonality['Magnitude'] = glacier_seasonality['MaxLength'] - glacier_seasonality['MinLength']\n",
    "\n",
    "    # add advance/retreat distributions to appropriate dataframes\n",
    "    max_advance_doy.loc[id] = glacier_seasonality['MaxDOY']\n",
    "    max_retreat_doy.loc[id] = glacier_seasonality['MinDOY']\n",
    "    annual_seasonality.loc[id] = glacier_seasonality['Magnitude']\n",
    "\n",
    "    # add glacier stats to main dataframe\n",
    "    # -- advance DOY\n",
    "    median_advance_doy = glacier_seasonality['MaxDOY'].median(skipna=True)\n",
    "    seasonality.at[id, 'Median Advance DOY'] = median_advance_doy\n",
    "    # -- advance Month Day\n",
    "    if not pd.isnull(seasonality.at[id, 'Median Advance DOY']):\n",
    "        median_advance_date = pd.to_datetime(f'2021{int(median_advance_doy)}', format='%Y%j')\n",
    "        seasonality.at[id, 'Median Advance Day'] = f'{median_advance_date.month_name()} {median_advance_date.day}'\n",
    "    # -- retreat DOY\n",
    "    median_retreat_doy = glacier_seasonality['MinDOY'].median(skipna=True)\n",
    "    seasonality.at[id, 'Median Retreat DOY'] = median_retreat_doy\n",
    "    # -- retreat Month Day\n",
    "    if not pd.isnull(seasonality.at[id, 'Median Retreat DOY']):\n",
    "        if median_retreat_doy > 365:\n",
    "            median_retreat_date = pd.to_datetime(f'2021{int(median_retreat_doy - 365)}', format='%Y%j')\n",
    "        else:\n",
    "            median_retreat_date = pd.to_datetime(f'2021{int(median_retreat_doy)}', format='%Y%j')\n",
    "        seasonality.at[id, 'Median Retreat Day'] = f'{median_retreat_date.month_name()} {median_retreat_date.day}'\n",
    "    # -- retreat duration\n",
    "    if not pd.isnull(seasonality.at[id, 'Median Advance Day']) and not pd.isnull(seasonality.at[id, 'Median Retreat Day']):\n",
    "        if median_retreat_date > median_advance_date:\n",
    "            seasonality.at[id, 'Retreat Duration'] = (median_retreat_date - median_advance_date).days\n",
    "        else:\n",
    "            median_retreat_date = median_retreat_date + pd.Timedelta(365, 'D')\n",
    "            seasonality.at[id, 'Retreat Duration'] = (median_retreat_date - median_advance_date).days\n",
    "    # -- magnitude\n",
    "    seasonality.at[id, 'Median Magnitude (km)'] = glacier_seasonality['Magnitude'].median(skipna=True)\n",
    "\n",
    "    # plot glacier seasonality with peaks/troughs and magnitude\n",
    "    # fig, ax = plt.subplots(figsize=(fw*2, 4))\n",
    "    # ax.plot(lengths_detrend, '.-', label='length')\n",
    "    # ax.plot(glacier_seasonality['MaxDate'], glacier_seasonality['MaxLength'], 'o', markersize=8,label=f'max advance (mdn={seasonality.loc[id][\"Median Advance Day\"]})')\n",
    "    # ax.plot(glacier_seasonality['MinDate'], glacier_seasonality['MinLength'], 'o', markersize=8,label=f'max retreat (mdn={seasonality.loc[id][\"Median Retreat Day\"]})')\n",
    "    # ax.vlines(x=glacier_seasonality['MaxDate'], ymin=glacier_seasonality['MinLength'],ymax=glacier_seasonality['MaxLength'], color='gray', label=f'magnitude (mdn={seasonality.loc[id][\"Median Magnitude (km)\"]*1000:.0f} m)')\n",
    "    # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # ax.set_ylabel('Length (km)')\n",
    "    # ax.set_xlabel('Date')\n",
    "    # ax.set_title(f'{glacier.getGlacierName()}, detrended')\n",
    "    # plt.savefig(f'../analysis/seasonality_detrended/{id}_seasonality.png', dpi=300,bbox_inches='tight')\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table S3: Timing and magnitude of seasonality for all glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: Regional breakdown of seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_seasonality = pd.DataFrame(index=['SW', 'CW', 'NW', 'NO', 'NE', 'SE', 'GrIS'], columns=['Median Advance DOY', 'Median Advance Day', 'Median Retreat DOY', 'Median Retreat Day', 'Retreat Duration', 'Median Magnitude (km)'])\n",
    "\n",
    "def get_regional_seasonality(GIDS_region):\n",
    "    ssn = seasonality[seasonality.index.isin(GIDS_region)]\n",
    "    med_adv = ssn['Median Advance DOY'].median()\n",
    "    med_adv_date = pd.to_datetime(f'2021{int(med_adv)}', format='%Y%j')\n",
    "    med_adv_day = f'{med_adv_date.month_name()} {med_adv_date.day}'\n",
    "    med_ret = ssn['Median Retreat DOY'].median()\n",
    "    med_ret_date = pd.to_datetime(f'2021{int(med_ret)}', format='%Y%j')\n",
    "    med_ret_day = f'{med_ret_date.month_name()} {med_ret_date.day}'\n",
    "    ret_dur = ssn['Retreat Duration'].median()\n",
    "    med_mag = ssn['Median Magnitude (km)'].median()\n",
    "    results = {\n",
    "        'Median Advance DOY': med_adv, 'Median Advance Day': med_adv_day, \n",
    "        'Median Retreat DOY': med_ret, 'Median Retreat Day': med_ret_day, \n",
    "        'Retreat Duration': ret_dur, 'Median Magnitude (km)': med_mag}\n",
    "    return results\n",
    "\n",
    "regional_seasonality.loc['SW'] = get_regional_seasonality(GIDS_SW)\n",
    "regional_seasonality.loc['CW'] = get_regional_seasonality(GIDS_CW)\n",
    "regional_seasonality.loc['NW'] = get_regional_seasonality(GIDS_NW)\n",
    "regional_seasonality.loc['NO'] = get_regional_seasonality(GIDS_NO)\n",
    "regional_seasonality.loc['NE'] = get_regional_seasonality(GIDS_NE)\n",
    "regional_seasonality.loc['SE'] = get_regional_seasonality(GIDS_SE)\n",
    "regional_seasonality.loc['GrIS'] = get_regional_seasonality(GIDS_seasonal)\n",
    "regional_seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3: Timing and magnitude of terminus position seasonality for select individual glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality for individual glaciers addressed in other studies\n",
    "# 3 - Jakobshavn\n",
    "# 17 - Rink\n",
    "# 120 - Daugaard-Jensen\n",
    "# 153 - Kangerlussuaq\n",
    "# 175 - Helheim\n",
    "seasonality.loc[[3, 17, 120, 153, 175]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE MAGNITUDES TO CARR ET AL (2013) AND MOON ET AL (2015) FOR DISCUSSION\n",
    "carr2013 = [34, 37, 38, 39, 40, 41, 42]\n",
    "moon2015 = [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 48, 49, 51, 52]\n",
    "carr_median = seasonality.loc[[x for x in carr2013 if x in seasonality.index]]['Median Magnitude (km)'].median()\n",
    "carr_mean = seasonality.loc[[x for x in carr2013 if x in seasonality.index]]['Median Magnitude (km)'].mean()\n",
    "moon_median = seasonality.loc[[x for x in moon2015 if x in seasonality.index]]['Median Magnitude (km)'].median()\n",
    "moon_mean = seasonality.loc[[x for x in moon2015 if x in seasonality.index]]['Median Magnitude (km)'].mean()\n",
    "\n",
    "print(f'Median magnitude for Carr2013 glaciers: {carr_median:.3f} km (mean: {carr_mean:.3f} km).')\n",
    "print(f'Median magnitude for Moon2015 glaciers: {moon_median:.3f} km (mean: {moon_mean:.3f} km).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE MAGNITUDES TO FRIED ET AL (2018) FOR DISCUSSION\n",
    "fried2018 = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18]\n",
    "fried_magnitudes = seasonality.loc[[x for x in fried2018 if x in seasonality.index]]\n",
    "fried_magnitudes.sort_values('Median Magnitude (km)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates of greatest advance/retreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print median dates and ranges of greatest advance and retreat\n",
    "\n",
    "# -- Median date of greatest advance (median by glacier, not by year - consistent with seasonality DF)\n",
    "median_advance_date = pd.to_datetime(\n",
    "    f'2021{int(max_advance_doy.median(axis=1, skipna=True).median())}', format='%Y%j')\n",
    "print(f'Median date of greatest advance: {median_advance_date.month_name()} {median_advance_date.day}')\n",
    "# -- Range of greatest advance dates (median by year, not by glacier)\n",
    "least_advance_date = pd.to_datetime(\n",
    "    f'{max_advance_doy.median(skipna=True).idxmin()}{int(max_advance_doy.median(skipna=True).min())}', format='%Y%j')\n",
    "great_advance_date = pd.to_datetime(\n",
    "    f'{max_advance_doy.median(skipna=True).idxmax()}{int(max_advance_doy.median(skipna=True).max())}', format='%Y%j')\n",
    "print(f'Range of greatest advance: {least_advance_date.month_name()} {least_advance_date.day} ({least_advance_date.year}) to {great_advance_date.month_name()} {great_advance_date.day} ({great_advance_date.year})')\n",
    "\n",
    "# Median date of greatest retreat (median by glacier, not by year - consistent with seasonality DF)\n",
    "median_retreat_date = pd.to_datetime(\n",
    "    f'2021{int(max_retreat_doy.median(axis=1, skipna=True).median())}', format='%Y%j')\n",
    "print(f'\\nMedian date of greatest retreat: {median_retreat_date.month_name()} {median_retreat_date.day}')\n",
    "# -- Range of greatest retreat dates (median by year, not by glacier)\n",
    "least_retreat_date = pd.to_datetime(\n",
    "    f'{max_retreat_doy.median(skipna=True).idxmin()}{int(max_retreat_doy.median(skipna=True).min())}', format='%Y%j')\n",
    "great_retreat_date = pd.to_datetime(\n",
    "    f'{max_retreat_doy.median(skipna=True).idxmax()}{int(max_retreat_doy.median(skipna=True).max())}', format='%Y%j')\n",
    "print(f'Range of greatest retreat: {least_retreat_date.month_name()} {least_retreat_date.day} ({least_retreat_date.year}) to {great_retreat_date.month_name()} {great_retreat_date.day} ({great_retreat_date.year})')\n",
    "\n",
    "median_retreat_duration = median_retreat_date - median_advance_date\n",
    "print(f'The median duration of retreat, differencing the median advance and retreat days, was {median_retreat_duration.days} days.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: Timing of greatest advance/retreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(fw, 3.5))\n",
    "\n",
    "# -- plot advance distribution each year\n",
    "annual_advances = [max_advance_doy[x].astype('float').dropna() for x in max_advance_doy]\n",
    "v1 = ax.violinplot(annual_advances, positions=YEARS, showextrema=False, showmedians=True)\n",
    "v1['cmedians'].set_color('black')\n",
    "for y in YEARS:\n",
    "    s1 = ax.scatter((y-0.08)*np.ones(len(max_advance_doy[y])), max_advance_doy[y], marker='.', s=2, color='tab:blue')\n",
    "# -- plot retreat distribution each year\n",
    "annual_retreats = [max_retreat_doy[x].astype('float').dropna() for x in max_retreat_doy]\n",
    "annual_retreats_nextyear = [max_retreat_doy[x].astype('float').dropna()-365 for x in max_retreat_doy]\n",
    "v2 = ax.violinplot(annual_retreats, positions=YEARS, showextrema=False, showmedians=True)\n",
    "v3 = ax.violinplot(annual_retreats_nextyear, positions=[x+1 for x in YEARS], showextrema=False, showmedians=False)\n",
    "v2['cmedians'].set_color('black')\n",
    "for pc in v3['bodies']:\n",
    "    pc.set_color('tab:orange')\n",
    "    pc.set_edgecolor(None)\n",
    "for y in YEARS:\n",
    "    # -- plot individual retreat points in their proper years\n",
    "    s2 = ax.scatter((y+0.08)*np.ones(len(max_retreat_doy[y])), max_retreat_doy[y], marker='.', s=2, color='tab:red')\n",
    "    # -- plot retreat points that spill over into the next year\n",
    "    ax.scatter((y+1.08)*np.ones(len(max_retreat_doy[y])), max_retreat_doy[y]-365, marker='.', s=2, color='tab:red')\n",
    "# -- plot duration of retreat period each year\n",
    "median_advance = [x.median() for x in annual_advances]\n",
    "median_retreat = [x.median() for x in annual_retreats]\n",
    "ax.vlines(x=YEARS, ymin=median_advance, ymax=median_retreat, color='black')\n",
    "# -- axes properties\n",
    "ax.set_yticks([1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335])\n",
    "ax.set_yticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
    "ax.set_ylim([1, 365])\n",
    "ax.set_xlim([2014.5, 2021.5])\n",
    "ax.set_xticks(YEARS)\n",
    "ax.set_title('Annual dates of maximum advance and retreat')\n",
    "ax.set_ylabel('Month')\n",
    "ax.set_xlabel('Year')\n",
    "ax.grid(axis='x')\n",
    "ax.legend(handles=[v1['bodies'][0], v2['bodies'][0], s1, s2], labels=['advance distribution', 'retreat distribution', 'advance dates', 'retreat dates'], ncol=2, loc='upper center', bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "plt.savefig('../figures/fig3_timing_advance_retreat.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get advance dates and median\n",
    "print([pd.to_datetime(f'{y}{int(x)}', format='%Y%j') for x, y in zip(median_advance, YEARS)])\n",
    "median_advance_date_fig3 = pd.to_datetime(f'2021{int(np.median(median_advance))}', format='%Y%j')\n",
    "print(f'Median: {median_advance_date_fig3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get retreat dates and median\n",
    "print([pd.to_datetime(f'{y}{int(x)}', format='%Y%j') for x, y in zip(median_retreat, YEARS)])\n",
    "median_retreat_date_fig3 = pd.to_datetime(f'2021{int(np.median(median_retreat))}', format='%Y%j')\n",
    "print(f'Median: {median_retreat_date_fig3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duration of retreat period (time between date of max advance and max retreat) each year\n",
    "retreat_duration = np.subtract(median_retreat, median_advance)\n",
    "print([x for x in zip(YEARS, retreat_duration)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The median retreat duration is {np.median(retreat_duration)} days (and the mean is {retreat_duration.mean()} days).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get retreat duration just in NW/CW Greenland to compare with MAR data from Black and Joughin (2022)\n",
    "max_advance_cnw = max_advance_doy.loc[[x for x in GIDS_CW+GIDS_NW if x in max_advance_doy.index]]\n",
    "max_retreat_cnw = max_retreat_doy.loc[[x for x in GIDS_CW+GIDS_NW if x in max_retreat_doy.index]]\n",
    "retreat_duration_cnw = max_retreat_cnw.median(skipna=True) - max_advance_cnw.median(skipna=True)\n",
    "retreat_duration_cnw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers about magnitude of terminus seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_magnitude = seasonality['Median Magnitude (km)'].astype('float')\n",
    "print(f'The mean terminus seasonality across Greenland is {median_magnitude.mean():.3f} km, and the median is {median_magnitude.median():.3f} km.')\n",
    "print(f'Terminus seasonality ranges from {median_magnitude.min():.3f}km at {all_glaciers[median_magnitude.idxmin()].getGlacierName()} to {median_magnitude.max():.3f}km at {all_glaciers[median_magnitude.idxmax()].getGlacierName()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Map and histogram of distribution of seasonal magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: also map (at least to look at) the locations of non-significant glaciers\n",
    "\n",
    "# Create geodataframe wtih glacier point location and median annual magnitude\n",
    "median_magnitude = pd.DataFrame(columns=['Glacier_ID', 'magnitude'], index=GIDS_seasonal)\n",
    "median_magnitude['Glacier_ID'] = seasonality.index.values\n",
    "median_magnitude['magnitude'] = seasonality['Median Magnitude (km)']\n",
    "points_mag = points.merge(median_magnitude, on='Glacier_ID')\n",
    "points_mag.magnitude = points_mag.magnitude.values.astype('float')\n",
    "\n",
    "# Initalize plot of terminus seasonality magnitude\n",
    "fig = plt.figure(figsize=(fw*2, 4))\n",
    "\n",
    "# Plot histogram of median annual variabilities\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.annotate(text='(a)', xy=(-0.15, 1.05), xycoords='axes fraction')\n",
    "ax1.hist(points_mag.magnitude, bins=np.arange(0, points_mag.magnitude.max()+0.5, 0.25), rwidth=0.95)\n",
    "ax1.set_xlabel('Median magnitude (km)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.grid(axis='x')\n",
    "\n",
    "# Plot map of median annual variabilities\n",
    "ax2 = fig.add_subplot(122, projection=ccrs.NorthPolarStereo(central_longitude=-45, true_scale_latitude=70))\n",
    "ax2.annotate(text='(b)', xy=(-0.15, 1.05), xycoords='axes fraction')\n",
    "# Plot glacier points with color and size scaled to magnitude\n",
    "coastline.plot(ax=ax2, color='gray', facecolor='gray', zorder=0)\n",
    "points_mag.plot(ax=ax2, column='magnitude', markersize=3*points_mag.magnitude.values, cmap='YlOrRd', legend=True, vmax=1.0, legend_kwds={'extend':'max', 'label':'Median magnitude (km)'})\n",
    "gl = ax2.gridlines(\n",
    "    transform=ccrs.Geodetic(),\n",
    "    draw_labels=True,\n",
    "    x_inline=False,\n",
    "    y_inline=False,\n",
    "    color='dimgray',\n",
    "    zorder=0.5)\n",
    "gl.top_labels = True\n",
    "gl.bottom_labels = False\n",
    "gl.left_labels = True\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'rotation': 0}\n",
    "gl.ylabel_style = {'rotation': 0}\n",
    "\n",
    "xmin, ymin, xmax, ymax = coastline.total_bounds\n",
    "ax2.set_xlim([xmin-20000, xmax+20000])\n",
    "ax2.set_ylim([ymin-20000, ymax+20000])\n",
    "\n",
    "# fig.suptitle('Magnitude of terminus position seasonality')\n",
    "\n",
    "plt.savefig('../figures/fig4_magnitude_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_mag.sort_values('magnitude')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_mag[points_mag['Glacier_ID'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{100 * len(median_magnitude[median_magnitude[\"magnitude\"] < 0.250]) / len(median_magnitude):.1f}% of glaciers have seasonal magnitude less than 250 m.')\n",
    "print(f'{100 * len(median_magnitude[median_magnitude[\"magnitude\"] > 0.500]) / len(median_magnitude):.1f}% of glaciers have seasonal magnitude greater than 500 m.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also map (at least to look at) the locations of non-significant glaciers\n",
    "\n",
    "# Initalize plot \n",
    "fig = plt.figure(figsize=(4,5))\n",
    "\n",
    "# Plot map of non-seasonal glaciers\n",
    "ax = fig.add_subplot(111, projection=ccrs.NorthPolarStereo(central_longitude=-45, true_scale_latitude=70))\n",
    "# Plot glacier points with color and size scaled to magnitude\n",
    "coastline.plot(ax=ax, color='gray', facecolor='gray', zorder=0)\n",
    "points.loc[GIDS_not_seasonal].plot(ax=ax, color='darkorange')\n",
    "gl = ax.gridlines(\n",
    "    transform=ccrs.Geodetic(),\n",
    "    draw_labels=True,\n",
    "    x_inline=False,\n",
    "    y_inline=False,\n",
    "    color='dimgray',\n",
    "    zorder=0.5)\n",
    "gl.top_labels = True\n",
    "gl.bottom_labels = False\n",
    "gl.left_labels = True\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'rotation': 0}\n",
    "gl.ylabel_style = {'rotation': 0}\n",
    "\n",
    "xmin, ymin, xmax, ymax = coastline.total_bounds\n",
    "ax.set_xlim([xmin-20000, xmax+20000])\n",
    "ax.set_ylim([ymin-20000, ymax+20000])\n",
    "ax.set_title('Non-seasonal glaciers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: identification of retreat events in six-day records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDENTIFY ALL RETREAT EVENTS AND SAVE TO DATAFRAMES FOR ALL, MONTHLY NUM, MONTHLY MAG\n",
    "\n",
    "retreat_threshold = 50 # in meters\n",
    "\n",
    "# Initialize dataframes to store data about timing, number, and magnitude of retreat events\n",
    "all_retreat_events = pd.DataFrame(index=pd.date_range(start='2015-01-01', end='2021-12-31', freq='1 D'), columns=GIDS6)\n",
    "num_retreat_events = pd.DataFrame(index=pd.MultiIndex.from_product([list(range(1,13)), list(YEARS)], names=['month', 'year']), columns=GIDS6)\n",
    "mag_retreat_events = pd.DataFrame(index=pd.MultiIndex.from_product([list(range(1,13)), list(YEARS)], names=['month', 'year']), columns=GIDS6)\n",
    "\n",
    "for id in GIDS6:\n",
    "    glacier = all_glaciers[id]\n",
    "    lengths = pd.Series(glacier.lengths.values, index=glacier.dates.values)\n",
    "    lengths_diff = lengths.diff()\n",
    "    # -- identify all retreat events (negative values)\n",
    "    potential_retreat_events = lengths_diff[lengths_diff < 0]\n",
    "    # -- identify all retreat events above a threshold (50m length)\n",
    "    likely_retreat_events = potential_retreat_events[potential_retreat_events < -retreat_threshold/1000]\n",
    "    # -- add data to retreat events dataframes\n",
    "    all_retreat_events[id] = likely_retreat_events\n",
    "    grouped_retreat_events = likely_retreat_events.groupby(\n",
    "        [likely_retreat_events.index.month, likely_retreat_events.index.year])\n",
    "    num_retreat_events[id] = grouped_retreat_events.count()\n",
    "    mag_retreat_events[id] = grouped_retreat_events.sum()*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RETREAT EVENTS FOR INDIVIDUAL GLACIERS\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=3, sharex=True, sharey=True, figsize=(fw*2, 9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for id in GIDS6:\n",
    "    glacier = all_glaciers[id]\n",
    "    glacier_retreats = all_retreat_events[id].dropna()\n",
    "    # -- plot timing and magnitude of all retreat events for each glacier\n",
    "    n = GIDS6.index(id)\n",
    "    ax[n].vlines(x=glacier_retreats.index, ymin=0, ymax=-1*glacier_retreats.values)\n",
    "    name = glacier.getGlacierName()\n",
    "    if '(' in name:\n",
    "        name_parts = name.split('(')\n",
    "        name_2line = name_parts[0] + '\\n(' + name_parts[1]\n",
    "        ax[n].set_title(f'#{id}: {name_2line}')\n",
    "    else:\n",
    "        ax[n].set_title(f'#{id}: {name}')\n",
    "    ax[n].grid('on')\n",
    "ax[-1].axis('off')\n",
    "\n",
    "# add big subplot for common axis labels\n",
    "ax1 = fig.add_subplot(111, frameon=False)\n",
    "ax1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "ax1.grid(False)\n",
    "ax1.set_ylabel('Retreat magnitude (km)')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "ax[-3].set_xticks(pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']))\n",
    "ax[-3].set_xticklabels(labels=['2015', '', '2017', '', '2019', '', '2021', ''])\n",
    "plt.savefig('../figures/figS4_retreat_events_individual.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CUMULATIVE RETREAT EVENTS OVER ALL GLACIERS, WITH/WITHOUT JAKOBSHAVN\n",
    "\n",
    "cumulative_daily_retreat = all_retreat_events.sum(axis=1)\n",
    "cumulative_daily_retreat_nojak = all_retreat_events.drop(3, axis=1).sum(axis=1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(fw*2, 4))\n",
    "ax1.annotate(text='(a)', xy=(-0.07, 1.05), xycoords='axes fraction')\n",
    "ax2.annotate(text='(b)', xy=(-0.07, 1.05), xycoords='axes fraction')\n",
    "# -- Plot cumulative daily retreat for all six-day glaciers\n",
    "ax1.vlines(x=cumulative_daily_retreat.index, ymin=0, ymax=-1*cumulative_daily_retreat.values)\n",
    "ax1.set_title('Combined retreat events')\n",
    "ax1.set_ylabel('Total magnitude (km)')\n",
    "ax1.set_ylim([0, 5])\n",
    "# -- Plot cumulative daily retreat for all six-day glaciers except Jakobshavn\n",
    "ax2.vlines(x=cumulative_daily_retreat_nojak.index, ymin=0, ymax=-1*cumulative_daily_retreat_nojak.values)\n",
    "ax2.set_title('Combined retreat events (Jakobshavn removed)')\n",
    "ax2.set_ylabel('Total magnitude (km)')\n",
    "ax2.set_ylim([0, 5])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/figS5_retreat_events_combined.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5: timing and magnitude of retreat events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT MONTHLY NUMBER AND MAGNITUDE OF RETREAT EVENTS\n",
    "\n",
    "# Get average number and magnitude of retreat events each month\n",
    "num_retreat_events.replace(np.nan, 0, inplace=True)\n",
    "mag_retreat_events.replace(np.nan, 0, inplace=True)\n",
    "monthly_num_retreat_events = num_retreat_events.groupby('month').mean().transpose()\n",
    "monthly_mag_retreat_events = mag_retreat_events.groupby('month').mean().transpose()\n",
    "\n",
    "# Violin plots of mean monthly number and magnitude of retreat events for each glacier\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharex=True, figsize=(fw*2, 3))\n",
    "ax1.annotate(text='(a)', xy=(-0.15, 1.05), xycoords='axes fraction')\n",
    "ax2.annotate(text='(b)', xy=(-0.15, 1.05), xycoords='axes fraction')\n",
    "# -- mean monthly number of retreat events\n",
    "v1 = ax1.violinplot(monthly_num_retreat_events, positions=range(1,13), showextrema=False, showmedians=True)\n",
    "v1['cmedians'].set_color('black')\n",
    "for m in range(1,13):\n",
    "    ax1.scatter(m*np.ones(len(monthly_num_retreat_events[m])), monthly_num_retreat_events[m], marker='.', s=2, color='tab:blue', alpha=0.5)\n",
    "ax1.set_xticks(range(1,13))\n",
    "ax1.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
    "ax1.set_ylabel('Monthly mean count')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_title('Mean monthly retreat events')\n",
    "ax1.grid(axis='x')\n",
    "# -- mean monthly magnitude of retreat events\n",
    "v2 = ax2.violinplot(monthly_mag_retreat_events, positions=range(1,13), showextrema=False, showmedians=True)\n",
    "v2['cmedians'].set_color('black')\n",
    "for m in range(1,13):\n",
    "    ax2.scatter(m*np.ones(len(monthly_mag_retreat_events[m])), monthly_mag_retreat_events[m], marker='.', s=2, color='tab:blue', alpha=0.5)\n",
    "ax2.set_ylabel('Monthly mean magnitude (km)')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_title('Mean monthly retreat magnitude')\n",
    "ax2.grid(axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/fig5_retreat_timing_magnitude.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which months have the most and least number of retreat events?\n",
    "monthly_num_retreat_events.median().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which months have the greatest and least magnitude of retreat events?\n",
    "monthly_mag_retreat_events.median().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between seasonal magnitude and glacier width?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT MAGNITUDE VS WIDTH FOR ALL SEASONAL GLACIERS \n",
    "\n",
    "# Create dataframe of glacier widths and magnitudes, with and without Humboldt glacier\n",
    "glacier_widths = pd.DataFrame(index=GIDS_seasonal, columns=['width', 'magnitude'], dtype='float')\n",
    "glacier_widths['width'] = glacier_widths.apply(lambda row: all_glaciers[row.name].widths.mean(), axis=1)\n",
    "glacier_widths['magnitude'] = seasonality['Median Magnitude (km)'].astype('float')\n",
    "glacier_widths = glacier_widths.dropna()\n",
    "glacier_widths_nohumboldt = glacier_widths[glacier_widths.index != 92]\n",
    "\n",
    "# Plot glacier magnitude vs width\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(fw*2, fw*1.1))\n",
    "ax1.annotate(text='(a)', xy=(-0.15, 1.05), xycoords='axes fraction')\n",
    "ax2.annotate(text='(b)', xy=(-0.15, 1.05), xycoords='axes fraction')\n",
    "# -- With Humboldt\n",
    "ax1.scatter(glacier_widths['width'], glacier_widths['magnitude'])\n",
    "slope, intercept, r_value, p_value, std_err = linregress(glacier_widths['width'], glacier_widths['magnitude'])\n",
    "ax1.plot(glacier_widths['width'], slope*glacier_widths['width']+intercept)\n",
    "ax1.annotate(text=f'y={slope:.2f}x + {intercept:.2f}\\nR$^2$={r_value**2:.3f}, p={p_value:.4f}', xy=(11, 1.5), xycoords='data')\n",
    "ax1.set_xlabel('Glacier width (km)')\n",
    "ax1.set_ylabel('Magnitude of terminus seasonality (km)')\n",
    "ax1.set_title('Width-magnitude relationship\\nwith Humboldt Glacier')\n",
    "# -- Without Humboldt\n",
    "ax2.scatter(glacier_widths_nohumboldt['width'], glacier_widths_nohumboldt['magnitude'])\n",
    "slope, intercept, r_value, p_value, std_err = linregress(glacier_widths_nohumboldt['width'], glacier_widths_nohumboldt['magnitude'])\n",
    "ax2.plot(glacier_widths_nohumboldt['width'], slope*glacier_widths_nohumboldt['width']+intercept)\n",
    "ax2.annotate(text=f'y={slope:.2f}x + {intercept:.2f}\\nR$^2$={r_value**2:.3f}, p={p_value:.4f}', xy=(4.5, 1.15), xycoords='data')\n",
    "ax2.set_xlabel('Glacier width (km)')\n",
    "ax2.set_ylabel('Magnitude of terminus seasonality (km)')\n",
    "ax2.set_title('Width-magnitude relationship\\nwithout Humboldt Glacier')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/figS6_width_magnitude.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_widths.sort_values('width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT RELATIONSHIP BETWEEN SMALL MAGNITUDE (<1KM) AND WIDTH\n",
    "# Seale et al. (2011) found that glaciers with variations <1km were typically <2km wide\n",
    "\n",
    "mag_below_1 = glacier_widths[glacier_widths['magnitude'] < 1]\n",
    "wid_below_2 = mag_below_1[mag_below_1['width'] > 2]\n",
    "print(f'Of {len(mag_below_1)} glaciers with seasonal magnitudes less than 1km, {len(wid_below_2)} glaciers ({100*len(wid_below_2)/len(mag_below_1):.1f}%) have widths greater than 2km.\\nThis could be biased in that we only looked at glaciers at least 1-1.5 km wide.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT WIDTHS FOR NON-SEASONAL GLACIERS\n",
    "glacier_widths_ns = pd.DataFrame(index=GIDS_not_seasonal, columns=['width'], dtype='float')\n",
    "glacier_widths_ns['width'] = glacier_widths_ns.apply(lambda row: all_glaciers[row.name].widths.mean(), axis=1)\n",
    "glacier_widths_ns.sort_values('width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between seasonal magnitude and glacier velocity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframe to store glacier mean velocities\n",
    "glacier_velocities = pd.DataFrame(index=GIDS, columns=['velocity'])\n",
    "\n",
    "# Load glacier velocity data following https://github.com/fastice/GrIMPNotebooks/blob/master/workingWithGrIMPVelocity.ipynb\n",
    "myVel = nisar.nisarVel()\n",
    "myVel.readDataFromTiff(velocity_file, url=False, readSpeed=False)\n",
    "\n",
    "# Loop over all glaciers\n",
    "for id in GIDS:\n",
    "    glacier = all_glaciers[id]\n",
    "\n",
    "    # Find x, y coordinates of most retreated terminus\n",
    "    most_retreated_xy = list(glacier.obsseries[glacier.areas.idxmin()].terminus.geoms[0].coords)\n",
    "    x = [c[0] for c in most_retreated_xy]\n",
    "    y = [c[1] for c in most_retreated_xy]\n",
    "\n",
    "    # Interpolate velocity to terminus coordinates\n",
    "    vxInterp, vyInterp, vvInterp = myVel.interp(x, y, units='m')\n",
    "\n",
    "    # Get mean velocity along terminus and add to dataframe\n",
    "    mean_velocity = np.nanmean(vvInterp)\n",
    "    glacier_velocities.loc[id] = mean_velocity\n",
    "\n",
    "# Add magnitudes to dataframe\n",
    "glacier_velocities['magnitude'] = seasonality['Median Magnitude (km)'].astype('float')\n",
    "\n",
    "glacier_velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot glacier magnitude vs velocity\n",
    "glacier_velocities['velocity_km'] = glacier_velocities['velocity']/1000\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(glacier_velocities['velocity_km'], glacier_velocities['magnitude'])\n",
    "slope, intercept, r_value, p_value, std_err = linregress(glacier_velocities.dropna()['velocity_km'].astype('float'), glacier_velocities.dropna()['magnitude'])\n",
    "ax.plot(glacier_velocities['velocity_km'], slope*glacier_velocities['velocity_km']+intercept)\n",
    "ax.annotate(text=f'y={slope:.2f}x + {intercept:.2f}\\nR$^2$={r_value**2:.3f}, p={p_value:.4f}', xy=(9, 1.5), xycoords='data')\n",
    "ax.set_xlabel('Mean velocity (km/yr)')\n",
    "ax.set_ylabel('Magnitude of terminus seasonality (km)')\n",
    "ax.set_title('Velocity-magnitude relationship')\n",
    "\n",
    "plt.savefig('../figures/figS7_velocity_magnitude.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get velocity of non-seasonal and seasonal glaciers\n",
    "vel_not_seasonal = glacier_velocities.loc[GIDS_not_seasonal]\n",
    "print(f'{100*len(vel_not_seasonal[vel_not_seasonal[\"velocity\"] < 1000])/len(GIDS_not_seasonal):.0f}% of non-seasonal glaciers have velocities below 1 km/yr.')\n",
    "print(f'The mean velocity of non-seasonal glaciers is {vel_not_seasonal[\"velocity_km\"].mean():.1f} km/yr (median is {vel_not_seasonal[\"velocity_km\"].median():.3f} km/yr)')\n",
    "\n",
    "vel_seasonal = glacier_velocities.loc[GIDS_seasonal]\n",
    "print(f'\\n{100*len(vel_seasonal[vel_seasonal[\"velocity\"] < 1000])/len(GIDS_seasonal):.0f}% of seasonal glaciers have velocities below 1 km/yr.')\n",
    "print(f'The mean velocity of seasonal glaciers is {vel_seasonal[\"velocity_km\"].mean():.1f} km/yr (median is {vel_seasonal[\"velocity_km\"].median():.3f} km/yr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
